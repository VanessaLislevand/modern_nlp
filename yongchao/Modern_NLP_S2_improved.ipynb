{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optional-cycling",
   "metadata": {},
   "source": [
    "# ModernNLP: #2\n",
    "* Discussing text restoration by [Sommerschield et al.](https://www.aclweb.org/anthology/D19-1668/).\n",
    "* Experimenting with a vanilla RNN encoder in Pytorch.\n",
    "* Performing text classification to predict the next character.\n",
    "* Instead of Ancient Greek text, we will use Plato in English. \n",
    "\n",
    "> Authored by John Pavlopoulos & Vasiliki Kougia\n",
    "\n",
    "> Modified by Yongchao Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infrared-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/chao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk; nltk.download('punkt')\n",
    "from urllib.request import urlopen\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random; random.seed(42)\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-sustainability",
   "metadata": {},
   "source": [
    "## Download and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "certified-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This paper's dataset takes too long to download; use Plato in English.\n",
    "data = urlopen(\"http://www.gutenberg.org/cache/epub/1497/pg1497.txt\").read().decode(\"utf8\")\n",
    "data = data[760:-19110] # cut editorial notes and licences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stable-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '!', '*', 'h', 'z', 'b', 'x', '?', 'd', '\\n', 'm', '\"', '2', 'v', '6', 'f', '7', '.', '(', '5', 'n', '3', '1', 'j', '4', '8', '0', ';', '+', 'w', 'o', 'k', 'r', 'l', ')', ' ', '/', 'g', 'y', '=', 'i', 'c', \"'\", 't', '9', 'a', 'p', 'u', 'q', ',', 's', 'e', '\\r', ':']\n"
     ]
    }
   ],
   "source": [
    "# tokenise the text, and remove any noise\n",
    "sentences = sent_tokenize(data)\n",
    "sentences = [s.strip().lower() for s in sentences]\n",
    "np.random.shuffle(sentences)\n",
    "\n",
    "# The vocabulary will comprise characters\n",
    "all_letters = list(set(\" \".join(sentences)))\n",
    "print(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pursuant-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(heraclitus said that the sun was extinguished every\n",
      "evening and relighted every morning.)\n"
     ]
    }
   ],
   "source": [
    "print (sentences[np.random.randint(len(sentences))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-export",
   "metadata": {},
   "source": [
    "### Define device to run on a local GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-barcelona",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fleet-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = [], []\n",
    "maxlen = 128\n",
    "for s in sentences:\n",
    "  if len(s)<10: \n",
    "    continue\n",
    "  txt = s[-maxlen:]\n",
    "  r = np.random.randint(low=5, high=min(maxlen, len(txt)))\n",
    "  inputs.append(txt[:r])\n",
    "  targets.append(txt[r])\n",
    "\n",
    "V = list(set(\"\".join(sentences)))\n",
    "targets_v = list(set(targets))\n",
    "# Split to train, val and test\n",
    "inputs_train, targets_train = inputs[:5000], targets[:5000] \n",
    "inputs_val, targets_val = inputs[5000:5500], targets[5000:5500]\n",
    "inputs_test, targets_test = inputs[5500:], targets[5500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorrect-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_encode(text, V, maxlen):\n",
    "  x = np.zeros(maxlen, dtype=int)\n",
    "  # Assign an index to each input character\n",
    "  for i, char in enumerate(text):\n",
    "    if i<maxlen:\n",
    "      x[i] = V.index(char) + 1 # Index 0 is used for padding\n",
    "  return x\n",
    "\n",
    "def output_encode(char, target_v):\n",
    "  # The output is the index of the ground truth character\n",
    "  o = target_v.index(char)\n",
    "  return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Encode input and output data of train, val and test\n",
    "encoded_inputs_train = [input_encode(s, V, maxlen) for s in inputs_train]\n",
    "lengths_train = [min(len(s), maxlen) for s in inputs_train]\n",
    "encoded_targets_train = [output_encode(t, targets_v) for t in targets_train]\n",
    "\n",
    "encoded_inputs_val = [input_encode(s, V, maxlen) for s in inputs_val]\n",
    "lengths_val = [min(len(s), maxlen) for s in inputs_val]\n",
    "encoded_targets_val = [output_encode(t, targets_v) for t in targets_val]\n",
    "\n",
    "encoded_inputs_test = [input_encode(s, V, maxlen) for s in inputs_test]\n",
    "lengths_test = [min(len(s), maxlen) for s in inputs_test]\n",
    "encoded_targets_test = [output_encode(t, targets_v) for t in targets_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "irish-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(inputs, lengths, targets, batch_size):\n",
    "  while True:\n",
    "    # Loop over all instances\n",
    "    d = list(zip(inputs, lengths, targets))\n",
    "    random.shuffle(d)\n",
    "    inputs, lengths, targets = zip(*d)\n",
    "    for i in range(0, len(inputs), batch_size):\n",
    "      x_inputs, x_lengths, y_targets = list(), list(), list()\n",
    "      # Loop over the images in the batch and yield their instances\n",
    "      for j in range(i, min(len(inputs), i + batch_size)):\n",
    "        x_inputs.append(inputs[j])\n",
    "        x_lengths.append(lengths[j])\n",
    "        y_targets.append(targets[j])\n",
    "\n",
    "      yield torch.LongTensor(x_inputs).to(device), torch.LongTensor(x_lengths), torch.tensor(y_targets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lonely-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(encoded_inputs_train, lengths_train, encoded_targets_train, batch_size)\n",
    "val_generator = generator(encoded_inputs_val, lengths_val, encoded_targets_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-sculpture",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "* RNN_Model\n",
    "* RNN_Encoder\n",
    "* RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "norman-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x, seq_lengths):\n",
    "\n",
    "        x, lengths  = self.encoder(x, seq_lengths)\n",
    "        x = self.decoder(x, lengths)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "protective-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=200, hidden_size=128,\n",
    "                embedding_tensor=None, padding_index=0, num_layers=1, \n",
    "                dropout=0, Max_leng=maxlen):\n",
    "        super(RNN_Encoder, self).__init__()      \n",
    "        self.hidden = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        # Define the layers in our architecture\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embed_size, \n",
    "                      padding_idx=padding_index, _weight=embedding_tensor)\n",
    "        self.drop_en = nn.Dropout(self.dropout)\n",
    "        self.rnn = nn.GRU(input_size=embed_size, \n",
    "                      hidden_size=self.hidden, \n",
    "                      num_layers=self.num_layers, \n",
    "                      batch_first=True, \n",
    "                      bidirectional=True)\n",
    "        self.attn = nn.Linear(self.hidden*2, self.hidden*2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, seq_lengths):\n",
    "        # Pass the input through the embedding layer\n",
    "        text_embed = self.embedding_layer(x)\n",
    "        # Apply dropout\n",
    "        x_embed = self.drop_en(text_embed)\n",
    "\n",
    "        # Pass the inputs to the GRU\n",
    "        packed_input = pack_padded_sequence(x_embed, seq_lengths, batch_first=True, \n",
    "                                        enforce_sorted=False)\n",
    "        packed_output, ht = self.rnn(packed_input)\n",
    "        # Get the hidden states of all time steps\n",
    " \n",
    "        out_rnn, lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        #Calculate attention weights, add it to the output vector\n",
    "        attn_weights = F.softmax(self.attn(out_rnn), dim=1)\n",
    "        out_rnn = attn_weights * out_rnn\n",
    "        out_rnn = self.drop_en(out_rnn)\n",
    "\n",
    "        \n",
    "\n",
    "        return out_rnn, lengths  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "looking-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve decoding by using RNN decoder\n",
    "class RNN_Decoder(nn.Module):\n",
    "    def __init__(self, num_output, hidden_size=128, dropout=0):\n",
    "        super(RNN_Decoder, self).__init__()      \n",
    "       \n",
    "\n",
    "        self.num_output = num_output\n",
    "        self.rnn = nn.GRU(input_size=hidden_size*2, hidden_size = hidden_size,\n",
    "                         batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, num_output)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        self.dropout = dropout\n",
    "        self.drop_de = nn.Dropout(self.dropout)\n",
    "    \n",
    "    def forward(self, x, seq_lengths):\n",
    "        \n",
    "        # add mask to change attention score to zero outside bound of real sentence length\n",
    "        mask = torch.arange(x.shape[1])[None, :] > seq_lengths[:, None]\n",
    "        x[mask] = 0\n",
    "        \n",
    "        output, ht = self.rnn(x)\n",
    "        \n",
    "        row_indices = torch.arange(0, x.size(0)).long()\n",
    "        col_indices = seq_lengths - 1\n",
    "        last_hidden_state = output[row_indices, col_indices, :]\n",
    "        \n",
    "        last_hidden_state = self.drop_de(last_hidden_state)\n",
    "\n",
    "        output = self.softmax(self.out(last_hidden_state))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "apart-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = RNN_Encoder(vocab_size=len(V)+1, dropout=0.2)\n",
    "decoder = RNN_Decoder(num_output=len(targets_v),dropout=0.2)\n",
    "model = RNN_Model(encoder, decoder)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "governmental-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "express-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3872b1ee54334d90bd899ce824f1b316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=20.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aa8204e2f84683a41b70943b280e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 1 val loss: 2.3880, val f1: 0.119\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31bc0d62fa849e2a985ddc311aa895a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 2 val loss: 2.1659, val f1: 0.210\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c698ac40d648d48a3a9d49dce69b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 3 val loss: 2.0651, val f1: 0.270\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce0a3d846a247389337216fbd3ebb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 4 val loss: 2.0240, val f1: 0.277\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda8ed3be80a48eb8458574aa0dd5e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 5 val loss: 2.0326, val f1: 0.285\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3c21600a7a48f4be1e15e7addef373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 6 val loss: 1.9427, val f1: 0.301\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a287662aebb44a2fb8f598a06f0fe511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 7 val loss: 1.9649, val f1: 0.293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2449bbc99829463d9ada9615c56ba6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 8 val loss: 1.8806, val f1: 0.318\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670d7f394b1346eeaa59c82defb446a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 9 val loss: 1.9571, val f1: 0.314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d0ce7dc6f346d0ab4aa47ce7892121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 10 val loss: 1.9877, val f1: 0.309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3bbb0e66724124ada7dc1952f6a3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 11 val loss: 2.0231, val f1: 0.314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b44285142a4ab49d2ba641f24987f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 12 val loss: 1.9979, val f1: 0.319\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a45bf34be747f096bc6460b78a0d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 13 val loss: 2.0888, val f1: 0.313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b4034c1ff34503ad19d8269da719ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 14 val loss: 2.0287, val f1: 0.340\n",
      "Save model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfb41be1da5438e87af4ec1d54e296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 15 val loss: 2.1156, val f1: 0.308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b3f6970eb14ac1bc04c0b1e8673e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 16 val loss: 2.1611, val f1: 0.308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13c2d4579f742bab610db9e6b34c1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 17 val loss: 2.1852, val f1: 0.314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa697fb9a1f49fe8753a26b4e4ff705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 18 val loss: 2.3062, val f1: 0.326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2b30a409ea4df08bb926a31213d1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 19 val loss: 2.2863, val f1: 0.323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ea89e38bc149a9a70f2be70795efa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 20 val loss: 2.3750, val f1: 0.306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and validate at the epoch's end, keep the best (based on val f1)\n",
    "epochs, highest_val_f1 = 20, 0\n",
    "\n",
    "for idx in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "  epoch = idx+1\n",
    "  #Switch to train mode\n",
    "  model.train()\n",
    "  for batch in tqdm(range(ceil(len(inputs_train)/batch_size)), desc=\"Iteration\"):\n",
    "    input_t, lengths_t, target_t = next(train_generator)\n",
    "    output = model(input_t,lengths_t)\n",
    "    loss = criterion(output,target_t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "  #Switch to eval mode\n",
    "  model.eval()\n",
    "  val_loss = []\n",
    "  val_targets = []\n",
    "  val_outputs = []\n",
    "  for i in range(ceil(len(inputs_val)/batch_size)):\n",
    "    input_t, lengths_t, target_t = next(val_generator)\n",
    "    output = model(input_t,lengths_t)\n",
    "    val_outputs.append(torch.argmax(output, dim=1))\n",
    "    val_targets.append(target_t)\n",
    "    val_loss.append(criterion(output,target_t).cpu().detach().numpy())\n",
    "  val_outputs = torch.cat(val_outputs)\n",
    "  val_targets = torch.cat(val_targets)        \n",
    "  f1 = f1_score(val_targets.cpu().numpy(), val_outputs.cpu().detach().numpy(), \n",
    "                average=\"macro\")\n",
    "  print(f\"EPOCH: {epoch} val loss: {sum(val_loss)/len(val_loss):.4f}, val f1: {f1:.3f}\")\n",
    "  if f1 > highest_val_f1:\n",
    "    print(\"Save model....\")\n",
    "    torch.save({'model_state_dict': model.state_dict()}, \"pytorch_model.bin\")\n",
    "    highest_val_f1 = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "engaging-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n",
    "encoder_e = RNN_Encoder(vocab_size=len(V)+1, dropout=0.2)\n",
    "decoder_e = RNN_Decoder(num_output=len(targets_v))\n",
    "model_e = RNN_Model(encoder, decoder)\n",
    "\n",
    "model_e.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "listed-census",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "certainly --> .\n",
      "certainly. --> .\n",
      "certainly.. --> .\n",
      "certainly... --> .\n",
      "certainly.... --> .\n",
      "certainly..... --> .\n",
      "certainly...... --> .\n",
      "certainly....... --> .\n",
      "certainly........ --> .\n",
      "certainly......... --> .\n",
      "certainly.......... --> d\n",
      "certainly..........d --> l\n",
      "certainly..........dl --> y\n",
      "certainly..........dly --> .\n",
      "certainly..........dly. --> .\n",
      "certainly..........dly.. --> .\n",
      "certainly..........dly... --> .\n",
      "certainly..........dly.... --> .\n",
      "certainly..........dly..... --> d\n",
      "certainly..........dly.....d --> i\n",
      "certainly..........dly.....di --> n\n",
      "certainly..........dly.....din --> g\n",
      "certainly..........dly.....ding -->  \n",
      "certainly..........dly.....ding  --> a\n",
      "certainly..........dly.....ding a --> n\n",
      "certainly..........dly.....ding an --> d\n",
      "certainly..........dly.....ding and -->  \n",
      "certainly..........dly.....ding and  --> a\n",
      "certainly..........dly.....ding and a --> r\n",
      "certainly..........dly.....ding and ar --> e\n",
      "certainly..........dly.....ding and are -->  \n",
      "certainly..........dly.....ding and are  --> b\n",
      "certainly..........dly.....ding and are b --> e\n",
      "certainly..........dly.....ding and are be --> t\n",
      "certainly..........dly.....ding and are bet --> i\n",
      "certainly..........dly.....ding and are beti --> n\n",
      "certainly..........dly.....ding and are betin --> g\n",
      "certainly..........dly.....ding and are beting -->  \n",
      "certainly..........dly.....ding and are beting  --> t\n",
      "certainly..........dly.....ding and are beting t --> h\n",
      "certainly..........dly.....ding and are beting th --> e\n",
      "certainly..........dly.....ding and are beting the -->  \n",
      "certainly..........dly.....ding and are beting the  --> t\n",
      "certainly..........dly.....ding and are beting the t --> h\n",
      "certainly..........dly.....ding and are beting the th --> e\n",
      "certainly..........dly.....ding and are beting the the -->  \n",
      "certainly..........dly.....ding and are beting the the  --> s\n",
      "certainly..........dly.....ding and are beting the the s --> a\n",
      "certainly..........dly.....ding and are beting the the sa --> i\n",
      "certainly..........dly.....ding and are beting the the sai --> d\n"
     ]
    }
   ],
   "source": [
    "model_e.eval()\n",
    "x=11\n",
    "prompt = inputs_test[x]\n",
    "text = prompt[:10]\n",
    "for i in range(50):\n",
    "  encoded_text = np.expand_dims(input_encode(text, V, maxlen), 0)\n",
    "  # Get the character with the largest probability as the next character\n",
    "  predicted = targets_v[model_e(torch.LongTensor(encoded_text).to(device), torch.LongTensor([len(text)])).argmax()][0]\n",
    "  print(f\"{text} --> {predicted}\")\n",
    "  # Add the predicted character to the input\n",
    "  text = text+predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-machinery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsv",
   "language": "python",
   "name": "dsv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
